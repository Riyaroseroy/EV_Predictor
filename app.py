# -*- coding: utf-8 -*-
"""project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xFYoAhYzb-ei-klFykWgQejWNMmW6WHD
"""

#EV Range Prediction System
import numpy as np
import pandas as pd
data = pd.read_csv('Electric_Vehicle_Population_Data.csv')

data.head()

data.info()

data.describe()

data.shape

"""unique values"""

print("\n Unique Values Count in Each Column:\n")
print(data.nunique())

#Electric Range Distribution
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 6))
sns.histplot(data['Electric Range'], bins=30, kde=True)
plt.title('Distribution of Electric Range')
plt.xlabel('Electric Range (miles)')
plt.ylabel('Frequency')
plt.show()

#Model Year Distribution
plt.figure(figsize=(10, 6))
sns.countplot(x='Model Year',data=data)
plt.title('Distribution of Model Year')
plt.xlabel('Model Year')
plt.xticks(rotation=45)
plt.ylabel('Count')
plt.show()

# Distribution of Make
plt.figure(figsize=(10, 6))
top_makes = data['Make'].value_counts().nlargest(10).index
sns.countplot(x='Make', data=data[data['Make'].isin(top_makes)])
plt.title('Distribution of Top 10 Makes')
plt.xlabel('Make')
plt.xticks(rotation=45)
plt.ylabel('Count')
plt.show()

"""boxplot

horizontal boxplot
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Example: Boxplot for Electric Range
plt.figure(figsize=(8, 4))
sns.boxplot(y=data['Electric Range'], color='skyblue')
plt.title("Boxplot - Electric Range")
plt.ylabel("Electric Range")
plt.grid(True)
plt.show()

"""similar base MSRP"""

plt.figure(figsize=(8, 4))
sns.boxplot(y=data['Base MSRP'], color='orange')
plt.title("Boxplot - Base MSRP")
plt.ylabel("Base MSRP")
plt.grid(True)
plt.show()

print("Shape of Data (Rows, Columns):", data.shape)
print("\nColumns:\n", data.columns.tolist())
print("\nData Types:\n", data.dtypes)

"""missing valus count"""

data.isnull().sum()

"""mode and mean"""

# 🔹 Fill CATEGORICAL columns using MODE
cat_cols = [
    'County',
    'City',
    'Electric Utility',
    'Postal Code',
    'Legislative District',
    '2020 Census Tract',
    'vehicle location'

]

for col in cat_cols:
    if col in data.columns:
        mode_val = data[col].mode()[0]
        data[col] = data[col].fillna(mode_val)
        print(f"✔ Filled missing in '{col}' using mode: {mode_val}")

# 🔹 Fill NUMERICAL columns using MEAN
num_cols = ['Electric Range', 'Base MSRP']

for col in num_cols:
    if col in data.columns:
        mean_val = data[col].mean()
        data[col] = data[col].fillna(mean_val)
        print(f"📊 Filled missing in '{col}' using mean: {mean_val:.2f}")

data.isnull().sum()

"""encoding"""

categorical_features = ['County', 'City', 'State', 'Make', 'Model', 'Electric Vehicle Type', 'Clean Alternative Fuel Vehicle (CAFV) Eligibility', 'Vehicle Location', 'Electric Utility']  # Update this list with your actual categorical columns

# Get dummy variables for categorical features
ev_encoded = pd.get_dummies(data, columns=categorical_features, drop_first=True)

ev_encoded.columns

"""dropping unwanted columns"""

data.drop(columns=['VIN (1-10)', 'DOL Vehicle ID'], inplace=True)

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

label_cols = data.select_dtypes(include='object').columns
le = LabelEncoder()

for col in label_cols:
    data[col] = le.fit_transform(data[col])
    print(f"Encoded column: {col}")

"""scaling

"""

numerical_features = ev_encoded.select_dtypes(include=['int64', 'float64']).columns.difference(['Electric Range'])

# Initialize the StandardScaler
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()

# Fit and transform the numerical features
ev_encoded[numerical_features] = scaler.fit_transform(ev_encoded[numerical_features])

ev_encoded[numerical_features]

"""outlier"""

def remove_outliers_iqr(dataframe, column):
    Q1 = dataframe[column].quantile(0.25)
    Q3 = dataframe[column].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    return dataframe[(dataframe[column] >= lower) & (dataframe[column] <= upper)]

# Remove outliers
for col in ['Electric Range', 'Base MSRP']:
    data = remove_outliers_iqr(data, col)
    print(f"Outliers removed from: {col}")

print("✅ Final Cleaned Data Shape:", data.shape)
print("\n✅ Remaining Missing Values:\n", data.isnull().sum())
print("\n✅ Data Preview:\n", data.head())

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns



import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split

import pandas as pd

"""Now that the data has been prepared, we can split it into training and testing sets to prepare it for model building and evaluation."""

import pandas as pd # or RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score  # or mean_squared_error for regression

y = data['Electric Range']
x = data.drop(columns=['Electric Range','2020 Census Tract'])

x

x.nunique()

x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=42)

from sklearn.ensemble import RandomForestRegressor

model = RandomForestRegressor(n_estimators=20, max_depth=10, random_state=42)
model.fit(x_train, y_train)

from sklearn.metrics import mean_squared_error, r2_score
y_pred = model.predict(x_valid)
mse = mean_squared_error(y_valid, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_valid, y_pred)
accuracy_percent = r2 * 100

print(f"📊 MSE: {mse:.2f}")
print(f"📉 RMSE: {rmse:.2f}")
print(f"✅ Accuracy (R² Score): {r2:.2f} or {accuracy_percent:.2f}%")

from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np


decision_tree = DecisionTreeRegressor(random_state=42)
decision_tree.fit(x_train,y_train)
y_pred = decision_tree.predict(x_valid)


mse = mean_squared_error(y_valid, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_valid, y_pred)

print(f"📊 MSE: {mse:.2f}")
print(f"📉 RMSE: {rmse:.2f}")
print(f"✅ Accuracy (R² Score): {r2:.2f}")

print(f"📊 MSE: {mse:.2f}")
print(f"📉 RMSE: {rmse:.2f}")
print(f"✅ Accuracy (R² Score): {r2:.2f} or {accuracy_percent:.2f}%")

"""linear regression"""

# linear regression
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np
from sklearn.impute import SimpleImputer

# Handle missing values using SimpleImputer
imputer = SimpleImputer(strategy='mean') # You can choose a different strategy like 'median' or 'most_frequent'
x_train_imputed = imputer.fit_transform(x_train)
x_valid_imputed = imputer.transform(x_valid)


# ✅ Train Linear Regression Model
model = LinearRegression()
model.fit(x_train_imputed, y_train)

# ✅ Predict
y_pred = model.predict(x_valid_imputed)

# ✅ Evaluate Model
mse = mean_squared_error(y_valid, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_valid, y_pred)
accuracy_percent = r2 * 100

print(f"MSE: {mse:.2f}")
print(f"RMSE: {rmse:.2f}")
print(f"R2 Score: {r2:.2f}")
print(f"Accuracy Percentage: {accuracy_percent:.2f}%")

from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import r2_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
import numpy as np


# Sample: x = features, y = target
# Make sure you have your dataset as 'x' and 'y'
# Example:
# x = your input features (numpy array or DataFrame)
# y = your target/output variable

# Step 1: Split your dataset
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Step 2: Handle missing values using SimpleImputer
imputer = SimpleImputer(strategy='mean') # You can choose a different strategy like 'median' or 'most_frequent'
x_train_imputed = imputer.fit_transform(x_train)
x_test_imputed = imputer.transform(x_test)


# Step 3: Scale your features (VERY IMPORTANT for SVR and KNN)
scaler = StandardScaler()
x_train_scaled = scaler.fit_transform(x_train_imputed)
x_test_scaled = scaler.transform(x_test_imputed)

# SVR Model (after scaling)
svr = SVR()
svr.fit(x_train_scaled, y_train)
y_pred_svr = svr.predict(x_test_scaled)
print("SVR R2 Score:", r2_score(y_test, y_pred_svr))

# KNN Model (after scaling)
knn = KNeighborsRegressor(n_neighbors=5)
knn.fit(x_train_scaled, y_train)
y_pred_knn = knn.predict(x_test_scaled)
print("KNN R2 Score:", r2_score(y_test, y_pred_knn))

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import r2_score

# Sample: X = features, y = target
# Make sure you have your dataset as 'X' and 'y'
# Example:
# X = your input features (numpy array or DataFrame)
# y = your target/output variable

# Step 1: Split your dataset
x_train, _test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Step 2: Scale your features (VERY IMPORTANT for SVR and KNN)
scaler = StandardScaler()
x_train_scaled = scaler.fit_transform(x_train)
x_test_scaled = scaler.transform(x_test)

# SVR Model (after scaling)
svr = SVR()
svr.fit(x_train_scaled, y_train)
y_pred_svr = svr.predict(x_test_scaled)
print("SVR R2 Score:", r2_score(y_test, y_pred_svr))

# KNN Model (after scaling)
knn = KNeighborsRegressor(n_neighbors=5)
knn.fit(x_train_scaled, y_train)
y_pred_knn = knn.predict(x_test_scaled)
print("KNN R2 Score:", r2_score(y_test, y_pred_knn))

import pandas as pd

# Step 1: Use the column names from your training dataset
feature_columns = x.columns.tolist()  # Make sure you've already defined X and trained the model

# Step 2: Take user input through the console
print("🔧 Enter EV details to predict range")

model_year = int(input("📅 Model Year (e.g., 2022): "))
price = float(input("💵 Base MSRP (price in dollars): "))

print("\n✅ Answer with 1 for Yes, 0 for No")

county_king = int(input("📍 Is it registered in King County? "))
make_tesla = int(input("🚗 Is the make Tesla? "))
model_model3 = int(input("📘 Is the model 'MODEL 3'? "))
bev = int(input("🔌 Is it a Battery Electric Vehicle (BEV)? "))
cafv_eligible = int(input("♻ Is it CAFV Eligible? "))
location_seattle = int(input("📌 Is it located at 47.60 -122.33? "))
utility_pse = int(input("⚡ Is the electric utility 'Puget Sound Energy Inc.'? "))

# Step 3: Store input in a dictionary
user_input = {
    'Model Year': model_year,
    'Base MSRP': price,
    'County_King': county_king,
    'Make_TESLA': make_tesla,
    'Model_MODEL 3': model_model3,
    'Electric Vehicle Type_Battery Electric Vehicle (BEV)': bev,
    'Clean Alternative Fuel Vehicle (CAFV) Eligibility_Clean Alternative Fuel Vehicle Eligible': cafv_eligible,
    'Vehicle Location_47.60 -122.33': location_seattle,
    'Electric Utility_PUGET SOUND ENERGY INC.': utility_pse
}

# Step 4: Create a blank input row with all zeros
input_data = pd.DataFrame([[0]*len(feature_columns)], columns=feature_columns)

# Step 5: Fill in actual input values
for key, value in user_input.items():
    if key in input_data.columns:
        input_data.at[0, key] = value

# Step 6: Predict using the model
predicted_range = model.predict(input_data)[0]

# Step 7: Show ±10% range
lower = predicted_range * 0.90
upper = predicted_range * 1.10

# Step 8: Display result
print(f"\n🔋 Predicted EV Range: {lower:.2f} – {upper:.2f} miles")



import pandas as pd
import numpy as np

# Make sure to run the data preparation cells before this cell!
# Re-load the data and perform necessary preprocessing
data = pd.read_csv('/content/Electric_Vehicle_Population_Data.csv')

# Fill missing values (using the same logic as before)
cat_cols = [
    'County',
    'City',
    'Electric Utility',
    'Postal Code',
    'Legislative District',
    '2020 Census Tract',
    'Vehicle Location' # Corrected column name
]

for col in cat_cols:
    if col in data.columns:
        mode_val = data[col].mode()[0]
        data[col] = data[col].fillna(mode_val)

num_cols = ['Electric Range', 'Base MSRP']

for col in num_cols:
    if col in data.columns:
        mean_val = data[col].mean()
        data[col] = data[col].fillna(mean_val)

# Drop unwanted columns
data.drop(columns=['VIN (1-10)', 'DOL Vehicle ID'], inplace=True)

# Encode categorical features (using LabelEncoder as before)
from sklearn.preprocessing import LabelEncoder
label_cols = data.select_dtypes(include='object').columns
le = LabelEncoder()

for col in label_cols:
    data[col] = le.fit_transform(data[col])

# Remove outliers
def remove_outliers_iqr(dataframe, column):
    Q1 = dataframe[column].quantile(0.25)
    Q3 = dataframe[column].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    return dataframe[(dataframe[column] >= lower) & (dataframe[column] <= upper)]

for col in ['Electric Range', 'Base MSRP']:
    data = remove_outliers_iqr(data, col)


# Define features (x) and target (y)
y = data['Electric Range']
x = data.drop(columns=['Electric Range','2020 Census Tract'])

# Create blank input row
input_data = pd.DataFrame([[0]*len(x.columns)], columns=x.columns)

print("\n🔋 EV Range Predictor using Decision Tree\n")

# Step-by-step input
input_data.at[0, 'County'] = float(input("County (e.g., 0–28): "))
input_data.at[0, 'City'] = float(input("City (e.g., 0–189): "))
input_data.at[0, 'State'] = float(input("State (usually 0 or 1): "))
input_data.at[0, 'Postal Code'] = float(input("Postal Code (e.g., 98125): "))
input_data.at[0, 'Model Year'] = int(input("Model Year (e.g., 2024): "))
input_data.at[0, 'Make'] = int(input("Make (e.g., 0–42): "))
input_data.at[0, 'Model'] = int(input("Model (e.g., 0–161): "))
input_data.at[0, 'Electric Vehicle Type'] = float(input("EV Type (0=BEV, 1=PHEV): "))
input_data.at[0, 'Clean Alternative Fuel Vehicle (CAFV) Eligibility'] = int(input("CAFV Eligible (0=Eligible, 1=Not Eligible, 2=Meets 2019): "))
input_data.at[0, 'Base MSRP'] = float(input("Base MSRP (e.g., 0.0): "))
input_data.at[0, 'Legislative District'] = float(input("Legislative District (e.g., 46.0): "))
input_data.at[0, 'Vehicle Location'] = float(input("Vehicle Location (e.g., 0–269): "))
input_data.at[0, 'Electric Utility'] = float(input("Electric Utility (e.g., 0–37): "))

# Predict range
predicted_range = model.predict(input_data)[0]
lower = predicted_range * 0.90
upper = predicted_range * 1.10

# Output
print(f"\n🔋 Predicted Electric Vehicle Range: {lower:.2f} – {upper:.2f} miles")

from google.colab import drive
drive.mount('/content/drive')